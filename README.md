# ğŸš€ Amazon ML Challenge 2023 ETL Pipeline

## **Project Overview**
This project focuses on building an **ETL (Extract, Transform, Load) pipeline** using data from the **Amazon ML Challenge 2023**. The primary goal is to **process large-scale data efficiently using Spark** and **store it in AWS for analysis and visualization**.

### **Ultimate Goal**
- Develop a **React-based frontend** for mock data collection and traffic simulation.
- Implement an **admin panel** for CRM data visualization and management.
- Build an **end-to-end data pipeline** to handle real-time and batch processing.

---

## **ğŸ“Œ ETL Pipeline Architecture**
Below is a high-level overview of the ETL pipeline:

![ETL Pipeline Diagram](./docs/etl_pipeline.png) *(Replace with actual image path in GitHub repo)*

### **1ï¸âƒ£ Extract (ë°ì´í„° ì¶”ì¶œ)**
- **Source**: Amazon ML Challenge dataset
- **Process**:
  - Load raw data from local storage or an external source.
  - Parse and structure the data using Spark.

### **2ï¸âƒ£ Transform (ë°ì´í„° ë³€í™˜)**
- **Process**:
  - Clean and preprocess data (handling missing values, normalization, etc.).
  - Generate meaningful metrics for further analysis.
  - Aggregate, filter, and optimize data.

### **3ï¸âƒ£ Load (ë°ì´í„° ì ì¬)**
- **Destination**:
  - AWS **S3** (for raw and processed data storage)
  - AWS **RDS** (for structured, relational data)
- **Process**:
  - Store cleaned data for future use in machine learning models and dashboards.

---

## **ğŸ—‚ Folder Structure**

project-etl/
â”‚
â”œâ”€â”€ data/               # Raw and processed data storage
â”œâ”€â”€ scripts/            # ETL scripts
â”‚   â”œâ”€â”€ extract.py      # Extracts data from source
â”‚   â”œâ”€â”€ transform.py    # Processes and cleans data
â”‚   â””â”€â”€ load.py         # Loads data into AWS
â”œâ”€â”€ dashboards/         # Tableau dashboards
â”œâ”€â”€ docker/             # Docker-related configurations
â”‚   â”œâ”€â”€ Dockerfile      # Defines the containerized environment
â”‚   â”œâ”€â”€ docker-compose.yml  # Multi-container setup
â”œâ”€â”€ frontend/           # React-based web application
â”‚   â”œâ”€â”€ src/            # Frontend source code
â”‚   â”œâ”€â”€ public/         # Static files
â”‚   â”œâ”€â”€ package.json    # Dependencies
â”œâ”€â”€ docs/               # Documentation files
â”‚   â”œâ”€â”€ etl_pipeline.png  # ETL pipeline diagram
â”œâ”€â”€ README.md           # Project documentation
â””â”€â”€ requirements.txt    # Python dependencies

---

## **ğŸ”§ Setup & Installation**
### **1ï¸âƒ£ Prerequisites**
Ensure you have the following installed:
- **Python 3.8+**
- **Docker 20.10+**
- **AWS CLI (configured)**
- **Tableau (for visualization)**

### **2ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-repo/project-etl.git
cd project-etl

3ï¸âƒ£ Run Docker

docker-compose up

4ï¸âƒ£ Run ETL Scripts

python scripts/extract.py
python scripts/transform.py
python scripts/load.py

5ï¸âƒ£ View Tableau Dashboard

Open Tableau and connect to the processed data stored in AWS RDS.

ğŸš€ Future Enhancements
	â€¢	âœ… Develop a frontend dashboard using React for better data visualization.
	â€¢	âœ… Simulate mock traffic and analyze user behavior trends.
	â€¢	âœ… Enhance automation for real-time data processing.
	â€¢	âœ… Deploy the project on AWS for full-scale production.
